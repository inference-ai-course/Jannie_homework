{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cafc73-1f17-4fbc-a470-ef2e167ee438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set. Ready to process papers.\n",
      "Loaded 50 papers from arxiv_clean.json\n",
      "Processed 10/50 papers -> last saved: papers_txt/2510.26575.txt\n",
      "Processed 20/50 papers -> last saved: papers_txt/2510.26345.txt\n",
      "Processed 30/50 papers -> last saved: papers_txt/2510.26202.txt\n",
      "Processed 40/50 papers -> last saved: papers_txt/2510.26020.txt\n",
      "Processed 50/50 papers -> last saved: papers_txt/2510.25816.txt\n",
      "Title: Gistify! Codebase-Level Understanding via Runtime Execution\n",
      "Authors: Hyunji Lee, Minseon Kim, Chinmay Singh, Matheus Pereira, Atharv Sonwane, Isadora White, Elias Stengel-Eskin, Mohit Bansal, Zhengyan Shi, Alessandro Sordoni, Marc-Alexandre Côté, Xingdi Yuan, Lucas Caccia\n",
      "Date: [Submitted on 30 Oct 2025]\n",
      "URL: https://arxiv.org/abs/2510.26790\n",
      "\n",
      "=== Abstract ===\n",
      "\n",
      "\n",
      "All papers processed. Check the folder: papers_txt\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook: Batch OCR + TXT Export for arXiv Abstracts\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Cell 1: Imports and Configuration\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "TASK1_JSON = \"arxiv_clean.json\"      # Input JSON from Task 1\n",
    "SCREENSHOT_DIR = \"screenshots\"       # Folder with screenshots (optional)\n",
    "OUTPUT_DIR = \"papers_txt\"            # Folder to save each paper as .txt\n",
    "OCR_ENABLED = True                    # Set False if no screenshots\n",
    "\n",
    "# Ensure output folders exist\n",
    "os.makedirs(SCREENSHOT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Configuration set. Ready to process papers.\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Cell 2: Load Task 1 JSON\n",
    "with open(TASK1_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    papers_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(papers_data)} papers from {TASK1_JSON}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Cell 3: Define function to combine abstract + OCR\n",
    "def process_paper(paper, screenshot_dir, output_dir, ocr_enabled=True):\n",
    "    \"\"\"\n",
    "    Combines Trafilatura abstract with optional OCR text,\n",
    "    preserves line breaks, and saves one .txt file per paper.\n",
    "    \"\"\"\n",
    "    url = paper.get(\"url\", \"\")\n",
    "    arxiv_id = url.split(\"/\")[-1]\n",
    "    \n",
    "    abstract_text = paper.get(\"abstract\", \"\").strip()\n",
    "    \n",
    "    # -----------------------------\n",
    "    # OCR from screenshot if enabled\n",
    "    # -----------------------------\n",
    "    if ocr_enabled:\n",
    "        screenshot_file = os.path.join(screenshot_dir, f\"{arxiv_id}.png\")\n",
    "        if os.path.exists(screenshot_file):\n",
    "            try:\n",
    "                img = Image.open(screenshot_file)\n",
    "                ocr_text = pytesseract.image_to_string(img, lang=\"eng\", config=\"--oem 1 --psm 3\")\n",
    "                # Preserve line breaks, remove empty lines\n",
    "                lines = [line.rstrip() for line in ocr_text.splitlines()]\n",
    "                ocr_text = \"\\n\".join(line for line in lines if line.strip())\n",
    "                if ocr_text:\n",
    "                    # Add separator to indicate OCR portion\n",
    "                    abstract_text += \"\\n\\n[OCR Text]\\n\\n\" + ocr_text\n",
    "            except Exception as e:\n",
    "                print(f\"OCR failed for {url}: {e}\")\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Save to .txt file\n",
    "    # -----------------------------\n",
    "    txt_filename = os.path.join(output_dir, f\"{arxiv_id}.txt\")\n",
    "    with open(txt_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        # Add header info\n",
    "        f.write(f\"Title: {paper.get('title','')}\\n\")\n",
    "        f.write(f\"Authors: {paper.get('authors','')}\\n\")\n",
    "        f.write(f\"Date: {paper.get('date','')}\\n\")\n",
    "        f.write(f\"URL: {url}\\n\")\n",
    "        f.write(\"\\n=== Abstract ===\\n\\n\")\n",
    "        f.write(abstract_text)\n",
    "    \n",
    "    return txt_filename\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Cell 4: Process all papers and save as individual .txt\n",
    "for i, paper in enumerate(papers_data, start=1):\n",
    "    txt_file = process_paper(paper, SCREENSHOT_DIR, OUTPUT_DIR, OCR_ENABLED)\n",
    "    if i % 10 == 0 or i == len(papers_data):\n",
    "        print(f\"Processed {i}/{len(papers_data)} papers -> last saved: {txt_file}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Cell 5: Optional: inspect a paper's txt\n",
    "sample_paper_id = papers_data[0][\"url\"].split(\"/\")[-1]\n",
    "sample_txt_path = os.path.join(OUTPUT_DIR, f\"{sample_paper_id}.txt\")\n",
    "\n",
    "with open(sample_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    print(f.read()[:1000])  # show first 1000 characters\n",
    "\n",
    "print(\"All papers processed. Check the folder:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98426d-b798-4b31-a2db-5ca556359912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
